#lang scheme

;;; exercise 1.9 ;;;

(define (inc x) (+ x 1))
(define (dec x) (- x 1))

(define (adder1 a b) (
    if (= a 0)
        b
        (inc (adder1 (dec a) b))
))

(define (adder2 a b) (
    if (= a 0)
        b
        (adder2 (dec a) (inc b))
))

#|
adder1在返回时进行一次inc计算, 在a=0前, 每次代换都会在表达式前加上(inc
递归计算过程

adder2在返回时不进行计算, a=0前, 每次代换都使得(+ a b)中的a减1, b加一
迭代计算过程

对比之后可以明白, 两者的代换过程虽然是统一的
但代换的结果会产生差异
adder1的代换结果会产生表达式结构上的变化
adder2的代换结果不改变表达式结构, 而改变a与b的值(实际上是改变了scope)

与常规语言不同的是, adder2中代换之后的表达式, 在求值之后就会直接得出值(代码描述的递归过程由于代换而变成了迭代地链式调用, 在最后一次调用表达式(+ 0 (a与b的实际和))后直接得出表达式的值, 代码描述的递归过程在计算时变成了迭代计算过程)
而常规语言中则是进行一次次的递归调用, 然后将表达式的值层层返回给调用栈上层(与代码的表述一致, 即递归计算过程与递归过程的代码描述保持一致)

|#

;;; wrong code ;;;

(define (inc x) (+ x 1))
(define (dec x) (- x 1))

(define (+ a b) (
    if (= a 0)
        b
        (inc (+ (dec a) b))
))

(define (+ a b) (
    if (= a 0)
        b
        (+ (dec a) (inc b))
))

#|
> (+ 0 20)
20

对正整数a而言
define (+ a b) 重写了+号, 又在if的分支中进行调用, 因此这是一个递归过程

整个程序看起来的逻辑是, 在每次过程调用时, 都让a的值减少1
然后再通过过程中的if来判断是否终止过程调用
每当a的值加少1时, 都会向b或(+ a b)的值增加1, 以保持结果不变

问题在于如何确定计算过程是递归计算过程还是迭代计算过程
得益于drRacket的内存占用情况显示, 很容易看出
(inc (+ (dec a) b))时, 内存占用不会发生明显变化
(+ (dec a) (inc b))时, 程序很快就会爆栈

迭代/递归计算过程的一个显著差异就是, 
递归计算过程需要耗费额外存储空间来维护栈信息, 而这些空间在栈信息计算和回填完成之后才会被释放
迭代计算过程主需要用常数数量的存储空间来存储当前计算过程所必须的信息, 并随迭代进行更新

显然前者是迭代计算过程, 而后者是递归计算过程

得出最终结论之后, 问题还剩下两个:
为什么递归过程没有正确地终止
为什么会出现递归和迭代计算过程的差异

先看代码, 看上去没有什么问题
在java中写了一段逻辑相同的代码, 跑起来也没有问题, 可以正确得出结果

进行步进调试后发现, 在(+ 1 1)进行时, 程序没有正确运行
在过程(+ a b)|a=1,b=1进行时
总是会一次又一次地对a=1,b=1的情况进行代换

最后发现
inc和dec的实现有问题, 不该用+号的
啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊啊
想了好久
|#

